{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Covid_prediction_CNN&Densenet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1jgOmgFBGsS"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InnfjbI7BvLl"
      },
      "source": [
        "#!pip install -q kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pHfuowxCUB0"
      },
      "source": [
        "#from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GckUK8zKCtLx"
      },
      "source": [
        "#files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAdXwyKiCvdO"
      },
      "source": [
        "#! mkdir ~/.kaggle\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjblD5WZDZrQ"
      },
      "source": [
        "#! cp kaggle.json ~/.kaggle/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dQsleyLDduL"
      },
      "source": [
        "#! chmod 600 ~/.kaggle/kaggle.json\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hx_0gioDhfW"
      },
      "source": [
        "#! kaggle competitions download <name-of-competition>\n",
        "#!kaggle datasets download -d jtiptj/chest-xray-pneumoniacovid19tuberculosis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_ryVWnpDy0e"
      },
      "source": [
        "!ls -a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAGB3GOqEW8P"
      },
      "source": [
        "ls\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ktPU95BEdPK"
      },
      "source": [
        "#!unzip chest-xray-pneumoniacovid19tuberculosis.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfWB62GuEiDr"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqkLHrxS1qpp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX33NcvE1qsj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VWyQDDJEwzQ"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGH-b4-PEzMn"
      },
      "source": [
        "cd ../\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmrFUQSOE4_t"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9DTyIHWE5s3"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "import random\n",
        "import os\n",
        "import cv2\n",
        "from IPython.display import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#from keras.utils import plot_model\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "import tensorflow as tf\n",
        "from keras.utils.vis_utils import plot_model\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "from keras import Model, layers\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "\n",
        "#from keras.optimizers import Adam, SGD\n",
        "from keras.layers import GlobalMaxPooling2D, GlobalAveragePooling2D, Dropout, Dense, Input, Conv2D, MaxPooling2D, Flatten,MaxPooling3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xBZD9ZR1FJ6"
      },
      "source": [
        "from keras import regularizers\n",
        "from keras.layers import Activation,Dense"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HISDymyG7EI"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvwaO0a1RcDx"
      },
      "source": [
        "#pull from datasets\n",
        "#   gauss\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/gaussian blur/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/gaussian blur/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOlkLQe4RvSY"
      },
      "source": [
        "#pull from datasets\n",
        "# tint\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/tinted images/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/tinted images/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-sRry_1Rzik"
      },
      "source": [
        "#pull from datasets\n",
        "# lens\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/lens flare/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/lens flare/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wV_PCR7UR2zc"
      },
      "source": [
        "#pull from datasets\n",
        "# lensandgauss\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/lensandgauss/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/lensandgauss/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fyfgHk3R8RS"
      },
      "source": [
        "#pull from datasets\n",
        "# lensandtint\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/lensandtint/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/lensandtint/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUkgRru7SBlG"
      },
      "source": [
        "#pull from datasets\n",
        "# tintandgauss\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/tintandgauss/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/tintandgauss/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVCQUu81SBcC"
      },
      "source": [
        "#pull from datasets\n",
        "#all\n",
        "#seg_train_folders = '/content/gdrive/MyDrive/datasets/All/Train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/gdrive/MyDrive/datasets/All/Test/'\n",
        "#seg_pred_folders = '/content/gdrive/MyDrive/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4rEVgmfSBaB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhcxU56HFlDO"
      },
      "source": [
        "#root_path = '/content/gdrive/MyDrive/Colab Notebooks/skin_images/'\n",
        "#train_pred_test_folders = os.listdir(root_path)\n",
        "\n",
        "#seg_train_folders = '/content/train/' #one more seg_train folder within\n",
        "#seg_test_folders = '/content/test/'\n",
        "#seg_pred_folders = '/content/testval/'\n",
        "quantity_tr = {} \n",
        "quantity_te = {}\n",
        "for folder in os.listdir(seg_train_folders):\n",
        "    quantity_tr[folder] = len(os.listdir(seg_train_folders+folder))\n",
        "\n",
        "for folder in os.listdir(seg_test_folders):\n",
        "    quantity_te[folder] = len(os.listdir(seg_test_folders+folder))\n",
        "    \n",
        "quantity_train = pd.DataFrame(list(quantity_tr.items()), index=range(0,len(quantity_tr)), columns=['class','count'])\n",
        "quantity_test = pd.DataFrame(list(quantity_te.items()), index=range(0,len(quantity_te)), columns=['class','count'])\n",
        "\n",
        "figure, ax = plt.subplots(1,2,figsize=(20,5))\n",
        "sns.barplot(x='class',y='count',data=quantity_train,ax=ax[0])\n",
        "sns.barplot(x='class',y='count',data=quantity_test,ax=ax[1])\n",
        "\n",
        "print(\"Number of images in the train set : \", sum(quantity_tr.values()))\n",
        "print(\"Number of images in the test set ; \",sum(quantity_te.values()))\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9G4XeNFG4EI"
      },
      "source": [
        "def save_history(history, model_name):\n",
        "    #convert the history.history dict to a pandas DataFrame:     \n",
        "    hist_df = pd.DataFrame(history.history) \n",
        "\n",
        "    # save to json:  \n",
        "    hist_json_file = model_name+'_history.json' \n",
        "    with open(hist_json_file, mode='w') as f:\n",
        "        hist_df.to_json(f)\n",
        "\n",
        "    # or save to csv: \n",
        "    hist_csv_file = model_name+'_history.csv'\n",
        "    with open(hist_csv_file, mode='w') as f:\n",
        "        hist_df.to_csv(f)\n",
        "        \n",
        "def plot_accuracy_from_history(history, isinception=False):\n",
        "    color = sns.color_palette()\n",
        "    if(isinception == False):\n",
        "        acc = history.history['acc']\n",
        "        val_acc = history.history['val_acc']\n",
        "    else:\n",
        "        acc = history.history['accuracy']\n",
        "        val_acc = history.history['val_accuracy']\n",
        "    \n",
        "\n",
        "    epochs = range(len(acc))\n",
        "\n",
        "    sns.lineplot(epochs, acc, label='Training Accuracy')\n",
        "    sns.lineplot(epochs, val_acc,label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "    \n",
        "def plot_loss_from_history(history):\n",
        "    color = sns.color_palette()\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    \n",
        "    epochs = range(len(loss))\n",
        "    \n",
        "    sns.lineplot(epochs, loss,label='Training Loss')\n",
        "    sns.lineplot(epochs, val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.show()\n",
        "    \n",
        "def do_history_stuff(history, history_file_name, isinception=False):\n",
        "    save_history(history, history_file_name)\n",
        "    plot_accuracy_from_history(history, isinception)\n",
        "    plot_loss_from_history(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0taVcFoP0CJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So80Tw-gP0O1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfDWO8qQJtzg"
      },
      "source": [
        "train_datagen = ImageDataGenerator( rescale = 1.0/255.,shear_range=0.2,zoom_range=0.2)\n",
        "\n",
        "# we are rescaling by 1.0/255 to normalize the rgb values if they are in range 0-255 the values are too high for good model performance. \n",
        "train_generator = train_datagen.flow_from_directory(seg_train_folders,\n",
        "                                                    batch_size=32,\n",
        "                                                    shuffle=True,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale = 1.0/255.) #we are only normalising to make the prediction, the other parameters were used for agumentation and train weights\n",
        "validation_generator = validation_datagen.flow_from_directory(seg_test_folders, shuffle=True, batch_size=1, class_mode='categorical', target_size=(150, 150))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nl6JUssJ1A0"
      },
      "source": [
        "inv_map_classes = {v: k for k, v in validation_generator.class_indices.items()}\n",
        "print(validation_generator.class_indices)\n",
        "print(inv_map_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvSrXHXxJ6m9"
      },
      "source": [
        "def show_few_images(number_of_examples=2, predict_using_model=None):\n",
        "    figure1, ax1 = plt.subplots(number_of_examples,len(os.listdir(seg_train_folders)), figsize=(20,4*number_of_examples))\n",
        "    ax1 = ax1.reshape(-1)\n",
        "    axoff_fun = np.vectorize(lambda ax:ax.axis('off'))\n",
        "    axoff_fun(ax1)\n",
        "    axs = 0\n",
        "    for i, folder in enumerate(os.listdir(seg_train_folders)):\n",
        "        image_ids = os.listdir(os.path.join(seg_train_folders,folder))\n",
        "        for j in [random.randrange(0, len(image_ids)) for i in range(0,number_of_examples)]:\n",
        "            \n",
        "            display = plt.imread(os.path.join(seg_train_folders,folder,image_ids[j]))\n",
        "            plt.axis('off')\n",
        "            ax1[axs].imshow(display)\n",
        "            title = 'True:'+folder\n",
        "            if(predict_using_model):\n",
        "                predicted_classname = inv_map_classes[np.argmax(inception_best_model.predict(np.array([display])))]\n",
        "                title = title+'\\nPredict :'+predicted_classname\n",
        "            ax1[axs].set_title(title)\n",
        "            axs=axs+1\n",
        "show_few_images(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrsEJ0Dt9HPu"
      },
      "source": [
        "from keras import applications\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg7bEFkw9Jat"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC0OQqlH9Jje"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T4D6i6tKAh4"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        " # epoch config\n",
        "benchmark_epoch = 20\n",
        "vgg_epoch = 20\n",
        "resnet_epoch = 20\n",
        "inception_epoch = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIV8ZGS49Sub"
      },
      "source": [
        "img_width, img_height = 150, 150\n",
        "nb_train_samples = 6000\n",
        "nb_validation_samples = 770\n",
        "epochs = 20\n",
        "batch_size = 32\n",
        "n_classes = 4\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FMMDN8P9SxH"
      },
      "source": [
        "from keras.applications import densenet\n",
        "def build_model():\n",
        "    base_model = densenet.DenseNet121(input_shape=(img_width, img_height, 3),\n",
        "                                     weights=\"imagenet\",\n",
        "                                     include_top=False,\n",
        "                                     pooling='avg')\n",
        "    for layer in base_model.layers:\n",
        "      layer.trainable = True\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
        "    x = Activation('relu')(x)\n",
        "    predictions = Dense(n_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcRrM-P99S0B"
      },
      "source": [
        "densenet_model = build_model()\n",
        "densenet_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-mcgPWsBet3"
      },
      "source": [
        "# from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
        "\n",
        "\n",
        "# early_stop = EarlyStopping(monitor='val_loss', patience=8, verbose=1, min_delta=1e-4)\n",
        "# reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=4, verbose=1, min_delta=1e-4)\n",
        "# callbacks_list = [early_stop, reduce_lr]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0LwoPwDYDE"
      },
      "source": [
        "filepath = \"densenet_-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=20, min_lr=0.000002)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
        "history = densenet_model.fit(train_generator,epochs=benchmark_epoch, verbose=1, validation_data = validation_generator,callbacks=[reduce_lr,early_stopping,checkpoint])\n",
        "\n",
        "densenet_model.save(filepath)\n",
        "do_history_stuff(history, 'densenet_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FrQiUK4UTU98"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mTnrG4tBe2B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuYHO_PuBe4q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSwYN1pEBe7U"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07mWOCXrBe91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNVowK65BfBZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqOlGzzB9S3Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIg_hdOEKI_g"
      },
      "source": [
        "#CNN architecture\n",
        "\n",
        "#random architecture\n",
        "benchmark_model = Sequential()\n",
        "# Input here is 4D array (batchsize, height, width, channels) - we have already created the train_generator with batch size 32\n",
        "# 32 Images of size each 150x150 with 3 color channels will be input into this layer\n",
        "benchmark_model.add(Conv2D(128, kernel_size=7, activation='relu', input_shape=(150,150,3)))\n",
        "benchmark_model.add(MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "benchmark_model.add(Conv2D(64, kernel_size=5, activation='relu'))\n",
        "benchmark_model.add(MaxPooling2D(pool_size=(4,4), strides=(2,2)))\n",
        "benchmark_model.add(Flatten())\n",
        "benchmark_model.add(Dense(128,activation='relu'))\n",
        "benchmark_model.add(Dense(4,activation='softmax'))\n",
        "\n",
        "benchmark_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "benchmark_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zq4mp3q5KNmh"
      },
      "source": [
        "filepath = \"bench_mark_-model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.05, patience=20, min_lr=0.000002)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)\n",
        "history = benchmark_model.fit(train_generator,epochs=benchmark_epoch, verbose=1, validation_data = validation_generator,callbacks=[reduce_lr,early_stopping,checkpoint])\n",
        "\n",
        "benchmark_model.save(filepath)\n",
        "do_history_stuff(history, 'benchmark_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsfqROgSVd60"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}